{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "In this notebook, i'll be using EEG Brainwave Dataset from kaggle. You can get the data from this [link.](https://www.kaggle.com/birdy654/eeg-brainwave-dataset-feeling-emotions/activity)\n",
    "\n",
    "Let's have a look at the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import bunch of libraries\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "brainwave_df = pd.read_csv('emotions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2132, 2549)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brainwave_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># mean_0_a</th>\n",
       "      <th>mean_1_a</th>\n",
       "      <th>mean_2_a</th>\n",
       "      <th>mean_3_a</th>\n",
       "      <th>mean_4_a</th>\n",
       "      <th>mean_d_0_a</th>\n",
       "      <th>mean_d_1_a</th>\n",
       "      <th>mean_d_2_a</th>\n",
       "      <th>mean_d_3_a</th>\n",
       "      <th>mean_d_4_a</th>\n",
       "      <th>...</th>\n",
       "      <th>fft_741_b</th>\n",
       "      <th>fft_742_b</th>\n",
       "      <th>fft_743_b</th>\n",
       "      <th>fft_744_b</th>\n",
       "      <th>fft_745_b</th>\n",
       "      <th>fft_746_b</th>\n",
       "      <th>fft_747_b</th>\n",
       "      <th>fft_748_b</th>\n",
       "      <th>fft_749_b</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.62</td>\n",
       "      <td>30.3</td>\n",
       "      <td>-356.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>26.3</td>\n",
       "      <td>1.070</td>\n",
       "      <td>0.411</td>\n",
       "      <td>-15.70</td>\n",
       "      <td>2.06</td>\n",
       "      <td>3.15</td>\n",
       "      <td>...</td>\n",
       "      <td>23.5</td>\n",
       "      <td>20.3</td>\n",
       "      <td>20.3</td>\n",
       "      <td>23.5</td>\n",
       "      <td>-215.0</td>\n",
       "      <td>280.00</td>\n",
       "      <td>-162.00</td>\n",
       "      <td>-162.00</td>\n",
       "      <td>280.00</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28.80</td>\n",
       "      <td>33.1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>25.8</td>\n",
       "      <td>22.8</td>\n",
       "      <td>6.550</td>\n",
       "      <td>1.680</td>\n",
       "      <td>2.88</td>\n",
       "      <td>3.83</td>\n",
       "      <td>-4.82</td>\n",
       "      <td>...</td>\n",
       "      <td>-23.3</td>\n",
       "      <td>-21.8</td>\n",
       "      <td>-21.8</td>\n",
       "      <td>-23.3</td>\n",
       "      <td>182.0</td>\n",
       "      <td>2.57</td>\n",
       "      <td>-31.60</td>\n",
       "      <td>-31.60</td>\n",
       "      <td>2.57</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.90</td>\n",
       "      <td>29.4</td>\n",
       "      <td>-416.0</td>\n",
       "      <td>16.7</td>\n",
       "      <td>23.7</td>\n",
       "      <td>79.900</td>\n",
       "      <td>3.360</td>\n",
       "      <td>90.20</td>\n",
       "      <td>89.90</td>\n",
       "      <td>2.03</td>\n",
       "      <td>...</td>\n",
       "      <td>462.0</td>\n",
       "      <td>-233.0</td>\n",
       "      <td>-233.0</td>\n",
       "      <td>462.0</td>\n",
       "      <td>-267.0</td>\n",
       "      <td>281.00</td>\n",
       "      <td>-148.00</td>\n",
       "      <td>-148.00</td>\n",
       "      <td>281.00</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.90</td>\n",
       "      <td>31.6</td>\n",
       "      <td>-143.0</td>\n",
       "      <td>19.8</td>\n",
       "      <td>24.3</td>\n",
       "      <td>-0.584</td>\n",
       "      <td>-0.284</td>\n",
       "      <td>8.82</td>\n",
       "      <td>2.30</td>\n",
       "      <td>-1.97</td>\n",
       "      <td>...</td>\n",
       "      <td>299.0</td>\n",
       "      <td>-243.0</td>\n",
       "      <td>-243.0</td>\n",
       "      <td>299.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>-12.40</td>\n",
       "      <td>9.53</td>\n",
       "      <td>9.53</td>\n",
       "      <td>-12.40</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.30</td>\n",
       "      <td>31.3</td>\n",
       "      <td>45.2</td>\n",
       "      <td>27.3</td>\n",
       "      <td>24.5</td>\n",
       "      <td>34.800</td>\n",
       "      <td>-5.790</td>\n",
       "      <td>3.06</td>\n",
       "      <td>41.40</td>\n",
       "      <td>5.52</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>38.1</td>\n",
       "      <td>38.1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>-17.60</td>\n",
       "      <td>23.90</td>\n",
       "      <td>23.90</td>\n",
       "      <td>-17.60</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2549 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   # mean_0_a  mean_1_a  mean_2_a  mean_3_a  mean_4_a  mean_d_0_a  mean_d_1_a  \\\n",
       "0        4.62      30.3    -356.0      15.6      26.3       1.070       0.411   \n",
       "1       28.80      33.1      32.0      25.8      22.8       6.550       1.680   \n",
       "2        8.90      29.4    -416.0      16.7      23.7      79.900       3.360   \n",
       "3       14.90      31.6    -143.0      19.8      24.3      -0.584      -0.284   \n",
       "4       28.30      31.3      45.2      27.3      24.5      34.800      -5.790   \n",
       "\n",
       "   mean_d_2_a  mean_d_3_a  mean_d_4_a  ...  fft_741_b  fft_742_b  fft_743_b  \\\n",
       "0      -15.70        2.06        3.15  ...       23.5       20.3       20.3   \n",
       "1        2.88        3.83       -4.82  ...      -23.3      -21.8      -21.8   \n",
       "2       90.20       89.90        2.03  ...      462.0     -233.0     -233.0   \n",
       "3        8.82        2.30       -1.97  ...      299.0     -243.0     -243.0   \n",
       "4        3.06       41.40        5.52  ...       12.0       38.1       38.1   \n",
       "\n",
       "   fft_744_b  fft_745_b  fft_746_b  fft_747_b  fft_748_b  fft_749_b     label  \n",
       "0       23.5     -215.0     280.00    -162.00    -162.00     280.00  NEGATIVE  \n",
       "1      -23.3      182.0       2.57     -31.60     -31.60       2.57   NEUTRAL  \n",
       "2      462.0     -267.0     281.00    -148.00    -148.00     281.00  POSITIVE  \n",
       "3      299.0      132.0     -12.40       9.53       9.53     -12.40  POSITIVE  \n",
       "4       12.0      119.0     -17.60      23.90      23.90     -17.60   NEUTRAL  \n",
       "\n",
       "[5 rows x 2549 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brainwave_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NEGATIVE', 'NEUTRAL', 'POSITIVE'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brainwave_df['label'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* So our data has 2132 datapoints. Each datapoint has 2548 input columns and target column named as **label**. Target can take one of three values.['NEGATIVE', 'NEUTRAL', 'POSITIVE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "sns.countplot(x = brainwave_df['label'], color='red')\n",
    "plt.title('Emotional sentiment class distributions')\n",
    "plt.ylabel('Class Counts')\n",
    "plt.xlabel('Class Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* As we can see from plot, all three class types are almost equally distributed. So there is no skewness in data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now let's drop target column to start out modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># mean_0_a</th>\n",
       "      <th>mean_1_a</th>\n",
       "      <th>mean_2_a</th>\n",
       "      <th>mean_3_a</th>\n",
       "      <th>mean_4_a</th>\n",
       "      <th>mean_d_0_a</th>\n",
       "      <th>mean_d_1_a</th>\n",
       "      <th>mean_d_2_a</th>\n",
       "      <th>mean_d_3_a</th>\n",
       "      <th>mean_d_4_a</th>\n",
       "      <th>...</th>\n",
       "      <th>fft_740_b</th>\n",
       "      <th>fft_741_b</th>\n",
       "      <th>fft_742_b</th>\n",
       "      <th>fft_743_b</th>\n",
       "      <th>fft_744_b</th>\n",
       "      <th>fft_745_b</th>\n",
       "      <th>fft_746_b</th>\n",
       "      <th>fft_747_b</th>\n",
       "      <th>fft_748_b</th>\n",
       "      <th>fft_749_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.62</td>\n",
       "      <td>30.3</td>\n",
       "      <td>-356.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>26.3</td>\n",
       "      <td>1.070</td>\n",
       "      <td>0.411</td>\n",
       "      <td>-15.70</td>\n",
       "      <td>2.06</td>\n",
       "      <td>3.15</td>\n",
       "      <td>...</td>\n",
       "      <td>74.3</td>\n",
       "      <td>23.5</td>\n",
       "      <td>20.3</td>\n",
       "      <td>20.3</td>\n",
       "      <td>23.5</td>\n",
       "      <td>-215.0</td>\n",
       "      <td>280.00</td>\n",
       "      <td>-162.00</td>\n",
       "      <td>-162.00</td>\n",
       "      <td>280.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28.80</td>\n",
       "      <td>33.1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>25.8</td>\n",
       "      <td>22.8</td>\n",
       "      <td>6.550</td>\n",
       "      <td>1.680</td>\n",
       "      <td>2.88</td>\n",
       "      <td>3.83</td>\n",
       "      <td>-4.82</td>\n",
       "      <td>...</td>\n",
       "      <td>130.0</td>\n",
       "      <td>-23.3</td>\n",
       "      <td>-21.8</td>\n",
       "      <td>-21.8</td>\n",
       "      <td>-23.3</td>\n",
       "      <td>182.0</td>\n",
       "      <td>2.57</td>\n",
       "      <td>-31.60</td>\n",
       "      <td>-31.60</td>\n",
       "      <td>2.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.90</td>\n",
       "      <td>29.4</td>\n",
       "      <td>-416.0</td>\n",
       "      <td>16.7</td>\n",
       "      <td>23.7</td>\n",
       "      <td>79.900</td>\n",
       "      <td>3.360</td>\n",
       "      <td>90.20</td>\n",
       "      <td>89.90</td>\n",
       "      <td>2.03</td>\n",
       "      <td>...</td>\n",
       "      <td>-534.0</td>\n",
       "      <td>462.0</td>\n",
       "      <td>-233.0</td>\n",
       "      <td>-233.0</td>\n",
       "      <td>462.0</td>\n",
       "      <td>-267.0</td>\n",
       "      <td>281.00</td>\n",
       "      <td>-148.00</td>\n",
       "      <td>-148.00</td>\n",
       "      <td>281.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.90</td>\n",
       "      <td>31.6</td>\n",
       "      <td>-143.0</td>\n",
       "      <td>19.8</td>\n",
       "      <td>24.3</td>\n",
       "      <td>-0.584</td>\n",
       "      <td>-0.284</td>\n",
       "      <td>8.82</td>\n",
       "      <td>2.30</td>\n",
       "      <td>-1.97</td>\n",
       "      <td>...</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>299.0</td>\n",
       "      <td>-243.0</td>\n",
       "      <td>-243.0</td>\n",
       "      <td>299.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>-12.40</td>\n",
       "      <td>9.53</td>\n",
       "      <td>9.53</td>\n",
       "      <td>-12.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.30</td>\n",
       "      <td>31.3</td>\n",
       "      <td>45.2</td>\n",
       "      <td>27.3</td>\n",
       "      <td>24.5</td>\n",
       "      <td>34.800</td>\n",
       "      <td>-5.790</td>\n",
       "      <td>3.06</td>\n",
       "      <td>41.40</td>\n",
       "      <td>5.52</td>\n",
       "      <td>...</td>\n",
       "      <td>114.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>38.1</td>\n",
       "      <td>38.1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>-17.60</td>\n",
       "      <td>23.90</td>\n",
       "      <td>23.90</td>\n",
       "      <td>-17.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2548 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   # mean_0_a  mean_1_a  mean_2_a  mean_3_a  mean_4_a  mean_d_0_a  mean_d_1_a  \\\n",
       "0        4.62      30.3    -356.0      15.6      26.3       1.070       0.411   \n",
       "1       28.80      33.1      32.0      25.8      22.8       6.550       1.680   \n",
       "2        8.90      29.4    -416.0      16.7      23.7      79.900       3.360   \n",
       "3       14.90      31.6    -143.0      19.8      24.3      -0.584      -0.284   \n",
       "4       28.30      31.3      45.2      27.3      24.5      34.800      -5.790   \n",
       "\n",
       "   mean_d_2_a  mean_d_3_a  mean_d_4_a  ...  fft_740_b  fft_741_b  fft_742_b  \\\n",
       "0      -15.70        2.06        3.15  ...       74.3       23.5       20.3   \n",
       "1        2.88        3.83       -4.82  ...      130.0      -23.3      -21.8   \n",
       "2       90.20       89.90        2.03  ...     -534.0      462.0     -233.0   \n",
       "3        8.82        2.30       -1.97  ...     -183.0      299.0     -243.0   \n",
       "4        3.06       41.40        5.52  ...      114.0       12.0       38.1   \n",
       "\n",
       "   fft_743_b  fft_744_b  fft_745_b  fft_746_b  fft_747_b  fft_748_b  fft_749_b  \n",
       "0       20.3       23.5     -215.0     280.00    -162.00    -162.00     280.00  \n",
       "1      -21.8      -23.3      182.0       2.57     -31.60     -31.60       2.57  \n",
       "2     -233.0      462.0     -267.0     281.00    -148.00    -148.00     281.00  \n",
       "3     -243.0      299.0      132.0     -12.40       9.53       9.53     -12.40  \n",
       "4       38.1       12.0      119.0     -17.60      23.90      23.90     -17.60  \n",
       "\n",
       "[5 rows x 2548 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df = brainwave_df['label']\n",
    "brainwave_df.drop('label',axis = 1,inplace = True)\n",
    "brainwave_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Here dimensionality of data-point is 2548. Due to curse of dimensionality, using any distance based model(like Logistic Regression, Linear SVM) is not a good idea.\n",
    "* So we'll use tree based ensembles bagging(RandomForest), boosting(XGBoost).\n",
    "* We'll use **10 fold cross validation** to train each model. we can use **accuracy** as our measurment metrics as data is not skewed. We'll compare mean of accuracy from each cv step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(brainwave_df, label_df, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracy for RandomForest:  0.98603280111233\n",
      "Test Score for RandomForest:  0.9786931818181818\n",
      "Wall time: 30.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Let's use RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "pipeline_random_forest = Pipeline(steps = [('random_forest', RandomForestClassifier(n_estimators = 100))])\n",
    "\n",
    "scores = cross_val_score(pipeline_random_forest, X_train, y_train, cv=10, scoring='accuracy')\n",
    "\n",
    "print('Cross Validation Accuracy for RandomForest: ', scores.mean())\n",
    "\n",
    "#Now let's see how well our model performs on test data\n",
    "pipeline_random_forest.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = pipeline_random_forest.predict(X_test)\n",
    "\n",
    "test_score = accuracy_score(y_test, y_predicted)\n",
    "\n",
    "print('Test Score for RandomForest: ', test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* So a basic RandomForest with 100 estimators has shown 98.6% of accuracy. Test accuracy is: 97.87%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now let's do hyperparameter tunning to get the best RandomForest model\n",
    "* First we'll do RandomizedSearch to narrow down our search for hyperparameters. Then we'll use GridSearchCV to get the best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "print(random_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 28.0min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 51.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "          fit_params=None, iid='warn', n_iter=100, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1400,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': 40,\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rf_random' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-2d19e1ec3b7b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0my_predicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf_random\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtest_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_predicted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rf_random' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_predicted = rf_random.predict(X_test)\n",
    "\n",
    "test_score = accuracy_score(y_test, y_predicted)\n",
    "\n",
    "print('Test Score for RandomForest: ', test_score) #98.4%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now let's do GridSearch to get the best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 162 candidates, totalling 486 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed: 10.0min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 28.4min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed: 66.9min\n",
      "[Parallel(n_jobs=-1)]: Done 486 out of 486 | elapsed: 86.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1h 26min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [False],\n",
    "    'max_depth': [40, 50, 60],\n",
    "    'max_features': ['auto', 'log2'],\n",
    "    'min_samples_leaf': [2, 3, 4],\n",
    "    'min_samples_split': [5, 7, 9],\n",
    "    'n_estimators': [1200, 1400, 2000]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestClassifier()\n",
    "# Instantiate the grid search model\n",
    "rf_grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)\n",
    "rf_grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rf_grid_search' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-06d7eaf89bed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrf_grid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'rf_grid_search' is not defined"
     ]
    }
   ],
   "source": [
    "rf_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rf_grid_search' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-79788bf5a2ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0my_predicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf_grid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtest_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_predicted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rf_grid_search' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_predicted = rf_grid_search.predict(X_test)\n",
    "\n",
    "test_score = accuracy_score(y_test, y_predicted)\n",
    "\n",
    "print('Test Score for RandomForest After GridSearch: ', test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
